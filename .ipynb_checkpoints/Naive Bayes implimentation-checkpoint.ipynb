{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Import proper modueles\"\"\"\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked\n",
      "0           0       3    0  22.0      1      0    7.2500       1.0\n",
      "1           1       1    1  38.0      1      0   71.2833       2.0\n",
      "2           1       3    1  26.0      0      0    7.9250       1.0\n",
      "3           1       1    1  35.0      1      0   53.1000       1.0\n",
      "4           0       3    0  35.0      0      0    8.0500       1.0\n",
      "5           0       3    0  -1.0      0      0    8.4583       3.0\n",
      "6           0       1    0  54.0      0      0   51.8625       1.0\n",
      "7           0       3    0   2.0      3      1   21.0750       1.0\n",
      "8           1       3    1  27.0      0      2   11.1333       1.0\n",
      "9           1       2    1  14.0      1      0   30.0708       2.0\n",
      "10          1       3    1   4.0      1      1   16.7000       1.0\n",
      "11          1       1    1  58.0      0      0   26.5500       1.0\n",
      "12          0       3    0  20.0      0      0    8.0500       1.0\n",
      "13          0       3    0  39.0      1      5   31.2750       1.0\n",
      "14          0       3    1  14.0      0      0    7.8542       1.0\n",
      "15          1       2    1  55.0      0      0   16.0000       1.0\n",
      "16          0       3    0   2.0      4      1   29.1250       3.0\n",
      "17          1       2    0  -1.0      0      0   13.0000       1.0\n",
      "18          0       3    1  31.0      1      0   18.0000       1.0\n",
      "19          1       3    1  -1.0      0      0    7.2250       2.0\n",
      "20          0       2    0  35.0      0      0   26.0000       1.0\n",
      "21          1       2    0  34.0      0      0   13.0000       1.0\n",
      "22          1       3    1  15.0      0      0    8.0292       3.0\n",
      "23          1       1    0  28.0      0      0   35.5000       1.0\n",
      "24          0       3    1   8.0      3      1   21.0750       1.0\n",
      "25          1       3    1  38.0      1      5   31.3875       1.0\n",
      "26          0       3    0  -1.0      0      0    7.2250       2.0\n",
      "27          0       1    0  19.0      3      2  263.0000       1.0\n",
      "28          1       3    1  -1.0      0      0    7.8792       3.0\n",
      "29          0       3    0  -1.0      0      0    7.8958       1.0\n",
      "..        ...     ...  ...   ...    ...    ...       ...       ...\n",
      "861         0       2    0  21.0      1      0   11.5000       1.0\n",
      "862         1       1    1  48.0      0      0   25.9292       1.0\n",
      "863         0       3    1  -1.0      8      2   69.5500       1.0\n",
      "864         0       2    0  24.0      0      0   13.0000       1.0\n",
      "865         1       2    1  42.0      0      0   13.0000       1.0\n",
      "866         1       2    1  27.0      1      0   13.8583       2.0\n",
      "867         0       1    0  31.0      0      0   50.4958       1.0\n",
      "868         0       3    0  -1.0      0      0    9.5000       1.0\n",
      "869         1       3    0   4.0      1      1   11.1333       1.0\n",
      "870         0       3    0  26.0      0      0    7.8958       1.0\n",
      "871         1       1    1  47.0      1      1   52.5542       1.0\n",
      "872         0       1    0  33.0      0      0    5.0000       1.0\n",
      "873         0       3    0  47.0      0      0    9.0000       1.0\n",
      "874         1       2    1  28.0      1      0   24.0000       2.0\n",
      "875         1       3    1  15.0      0      0    7.2250       2.0\n",
      "876         0       3    0  20.0      0      0    9.8458       1.0\n",
      "877         0       3    0  19.0      0      0    7.8958       1.0\n",
      "878         0       3    0  -1.0      0      0    7.8958       1.0\n",
      "879         1       1    1  56.0      0      1   83.1583       2.0\n",
      "880         1       2    1  25.0      0      1   26.0000       1.0\n",
      "881         0       3    0  33.0      0      0    7.8958       1.0\n",
      "882         0       3    1  22.0      0      0   10.5167       1.0\n",
      "883         0       2    0  28.0      0      0   10.5000       1.0\n",
      "884         0       3    0  25.0      0      0    7.0500       1.0\n",
      "885         0       3    1  39.0      0      5   29.1250       3.0\n",
      "886         0       2    0  27.0      0      0   13.0000       1.0\n",
      "887         1       1    1  19.0      0      0   30.0000       1.0\n",
      "888         0       3    1  -1.0      1      2   23.4500       1.0\n",
      "889         1       1    0  26.0      0      0   30.0000       2.0\n",
      "890         0       3    0  32.0      0      0    7.7500       3.0\n",
      "\n",
      "[891 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Edit the data accordingly\"\"\"\n",
    "data = pd.read_csv(\"edit_train.csv\")\n",
    "\n",
    "# \"\"\"Replace sex with binary variables 0 and 1\"\"\"\n",
    "data['Sex'] = data['Sex'].replace('male', 0)\n",
    "data['Sex'] = data['Sex'].replace('female', 1)\n",
    "\n",
    "\n",
    "\"\"\"Replace S, C, Q loacation variables of embarkement with 1,2,3 respecitley\"\"\"\n",
    "data['Embarked'] = data['Embarked'].replace('S', 1)\n",
    "data['Embarked'] = data['Embarked'].replace('C', 2)\n",
    "data['Embarked'] = data['Embarked'].replace('Q', 3)\n",
    "data['Embarked'] = data['Embarked'].replace('nan', -1)\n",
    "\n",
    "# \"\"\"Replace empty ages with -1?\"\"\"\n",
    "data['Age'] = data['Age'].replace('NaN', -1)\n",
    "print(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame.as_matrix(data)\n",
    "\n",
    "half = int(len(X)/2)\n",
    "\n",
    "train = X[:half,:]\n",
    "\n",
    "test = X[half:,:]\n",
    "\n",
    "quarter = int(len(X)/4)\n",
    "\n",
    "train_2 = X[:quarter,:]\n",
    "\n",
    "test_2 = X[quarter:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strictly continous missclassification rate: 20.85 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Naive Bayes normal prior with strictly continious variables\"\"\"\n",
    "\n",
    "\n",
    "def seperate_class(data,d):\n",
    "    zero_list = []\n",
    "    one_list = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i,0]==0:\n",
    "            zero_list.append(data[i,1:d+1])\n",
    "        elif data[i,0]==1:  \n",
    "            one_list.append(data[i,1:d+1])\n",
    "    return np.array(zero_list), np.array(one_list)\n",
    "\n",
    "def general_class_mean(data,d):\n",
    "    zero_list, one_list = seperate_class(data,d)\n",
    "            \n",
    "    \n",
    "    return np.mean(np.array(zero_list),axis = 0), np.mean(np.array(one_list), axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def general_class_covariance(data,d):\n",
    "    zero_list, one_list = seperate_class(data,d)\n",
    "\n",
    "    return np.cov(np.array(zero_list).T), np.cov(np.array(one_list).T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def general_multivariate_guassian(data,classfication,points,d):\n",
    "    zero_average, one_average = general_class_mean(data,d)\n",
    "    \n",
    "    zero_covarance, one_covariance = general_class_covariance(data,d)\n",
    "    \n",
    "    if classfication == 0:\n",
    "        return multivariate_normal.pdf(points, mean = zero_average, cov = zero_covarance)\n",
    "    elif classfication == 1:\n",
    "        return multivariate_normal.pdf(points, mean = one_average, cov = one_covariance)\n",
    "\n",
    "    \n",
    "def general_five_nine_prediction(points,classification,data,d):\n",
    "    \n",
    "    class_conditional = general_multivariate_guassian(data,classification,points,d)\n",
    "    \n",
    "    zero_list, one_list = seperate_class(data,d)\n",
    "    \n",
    "    if classification == 0:\n",
    "        return (len(zero_list)/len(data))*class_conditional\n",
    "    elif classification ==1:\n",
    "        return (len(one_list)/len(data))*class_conditional\n",
    "    \n",
    "\n",
    "def general_five_nine_missclass(data,training_data,d):\n",
    "    predictions = []\n",
    "    missclass = 0\n",
    "    \n",
    "    test_lst = []\n",
    "    \n",
    "    for vector in data:\n",
    "        test_lst.append(list(vector[1:d+1]))\n",
    "    \n",
    "    for vector in test_lst:\n",
    "        zero_probablity = general_five_nine_prediction(vector,0,training_data,d)\n",
    "        one_probablity = general_five_nine_prediction(vector,1,training_data,d)\n",
    "        \n",
    "        if zero_probablity > one_probablity:\n",
    "            predictions.append(0)\n",
    "        elif zero_probablity < one_probablity:\n",
    "            predictions.append(1)\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != data[i][0]:\n",
    "            missclass += 1\n",
    "            \n",
    "    missclass = (missclass/len(data))*100\n",
    "    print('Strictly continous missclassification rate:',np.around(missclass, decimals =2),'%')\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"There are 7 features\"\"\"\n",
    "general_five_nine_missclass(test,train,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed discrete/continuous misclassification: 11.45 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Naive Bayes normal prior with continious and discrete variables\"\"\"\n",
    "\n",
    "\"\"\"We will note all features of x are discrete aside from X[:,6], or the fare,\n",
    "which is continous. We will thus impliment a discrete meodel on all other \n",
    "features and a continous with a multivariate normal on the fare and compare\n",
    "these results to those of a stricly continous model\"\"\"\n",
    "\n",
    "def class_conditional_array(data):\n",
    "    \"\"\"seperate the data by classes as feature vectors\"\"\"\n",
    "    zero_list, one_list = seperate_class(data,len(data[0]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"delete the fare and classes from data\"\"\"\n",
    "    new_one = np.column_stack((one_list[:,:5],one_list[:,6:]))\n",
    "    \n",
    "    new_zero = np.column_stack((zero_list[:,:5],zero_list[:,6:]))\n",
    "\n",
    "    \n",
    "    \"\"\"initialize our class conditional array\"\"\"\n",
    "    zero_CCA = np.zeros((81,len(new_zero[0])))\n",
    "    \n",
    "    one_CCA = np.zeros((81,len(new_one[0])))\n",
    "    \n",
    "    for vector in new_one:\n",
    "        for feature in range(len(vector)):\n",
    "            s = int(vector[feature])\n",
    "            if s >= -1:\n",
    "                one_CCA[s][feature]+=1\n",
    "    \n",
    "    \n",
    "    for vector in new_zero:\n",
    "        for feature in range(len(vector)):\n",
    "            s = int(vector[feature])\n",
    "            if s >= -1:\n",
    "                zero_CCA[s][feature]+=1\n",
    "    \n",
    "    one_CCA = one_CCA/len(one_list)\n",
    "    zero_CCA = zero_CCA/len(zero_list)\n",
    "    \n",
    "\n",
    "    return zero_CCA, one_CCA\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def cont_discrete_misslass(test_data,training_data):\n",
    "    predictions = []\n",
    "    truth = test_data[:,0]\n",
    "    missclass = 0\n",
    "    \n",
    "    \"\"\"import the class_conditional_array (CCA) trained on training set\"\"\"\n",
    "    \n",
    "    zero_CCA, one_CCA = class_conditional_array(training_data)\n",
    "    \n",
    "    \"\"\"save the mean and variance of the fare of training set to make \n",
    "    a silgle variate guassian of this feature\"\"\"\n",
    "    zero_train, one_train = seperate_class(training_data,len(training_data[0]))\n",
    "    \n",
    "    zero_mean = np.mean(zero_train[:,5])\n",
    "    \n",
    "    zero_cov = np.cov(zero_train[:,5])\n",
    "    \n",
    "    one_mean = np.mean(one_train[:,5])\n",
    "    \n",
    "    one_cov = np.cov(one_train[:,5])\n",
    "    \n",
    "    \"\"\"Remove the classification cus no cheating!\"\"\"\n",
    "    test_data = test_data[:,1:]\n",
    "    \n",
    "    \"\"\"make predictions from avalible data structures\"\"\"\n",
    "    for vector in test_data: #5 is fare\n",
    "        one_prob = 1 \n",
    "        zero_prob = 1 \n",
    "        \n",
    "        \n",
    "        for index in range(len(vector)):\n",
    "            if index == 5:\n",
    "                one_prob *= multivariate_normal.pdf(vector[5], mean = one_mean, cov = one_cov)\n",
    "                zero_prob *= multivariate_normal.pdf(vector[5], mean = zero_mean, cov = zero_cov)\n",
    "                \n",
    "            elif index <5:\n",
    "                s = int(vector[index])\n",
    "                one_prob *= one_CCA[s][index]\n",
    "                zero_prob *= zero_CCA[s][index]\n",
    "            elif index >5:\n",
    "                s = int(vector[index])\n",
    "                one_prob *= one_CCA[s][index-1]\n",
    "                zero_prob *= zero_CCA[s][index-1]\n",
    "        if one_prob > zero_prob:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    \n",
    "    for index in range(len(predictions)):\n",
    "        if predictions[index] != truth[index]:\n",
    "            missclass += 1\n",
    "            \n",
    "    missclass = missclass/len(data)*100\n",
    "            \n",
    "    print('Mixed discrete/continuous misclassification:', np.around(missclass, decimals = 2), '%')\n",
    "\n",
    "\n",
    "\n",
    "cont_discrete_misslass(test,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This mixed model is twice as good when we take into consideration what features are discrete or continous rather than just treating all variables as continous! That's amazing!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
